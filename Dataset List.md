## List of Datasets for Machine Lipreading Research

#### LipNet

The Primary Dataset used for this research was LipNet.  

The LipNet dataset is a collection of videos and their corresponding transcriptions that were used to train a deep neural network for lip reading. 
The dataset was created by researchers at the University of Oxford and contains 1,000 videos of people speaking words and phrases from a vocabulary 
of over 50 words.

Each video is approximately 2-3 seconds long and was recorded at 25 frames per second. The videos were captured with a high-speed camera that was 
focused on the speaker's face and upper body. The dataset also includes the corresponding text transcriptions for each video.

You can find the LipNet dataset at the following link:
https://www.robots.ox.ac.uk/~vgg/data/lip_reading/lip_reading_datasets.html


Experimentation with other datasets included the following list.

This is a list of publicly available datasets sampled and studied for this machine lipreading research. 
Each dataset is accompanied by a brief description and a link to the website where it can be downloaded.

1. **LRS3-TED**
- Description: A large-scale dataset of TED talk videos, with corresponding transcripts and time-aligned word-level annotations.
- Link: http://www.robots.ox.ac.uk/~vgg/data/lip_reading/lrs3-ted/

2. **GRID**
- Description: A dataset of video sequences of speakers saying words from a closed-set vocabulary, recorded with a high-quality camera and synchronized audio.
- Link: https://spandh.dcs.shef.ac.uk/gridcorpus/

3. **LRW**
- Description: A dataset of video sequences of speakers saying words from a closed-set vocabulary, recorded with a high-quality camera and synchronized audio.
- Link: http://www.robots.ox.ac.uk/~vgg/data/lip_reading/lrw1.html

4. **OuluVS2**
- Description: A dataset of video sequences of speakers saying sentences, recorded with a high-quality camera and synchronized audio.
- Link: https://www.oulu.fi/cmvs/node/41344

5. **MIRACL-VC1**
- Description: A dataset of video sequences of speakers saying isolated digits, recorded with a high-quality camera and synchronized audio.
- Link: http://www.robots.ox.ac.uk/~vgg/data/lip_reading/miraclevc1.html

6. **CUAVE**
- Description: A dataset of video sequences of speakers saying words and phrases, recorded with a low-quality camera and synchronized audio.
- Link: https://www.ee.columbia.edu/~dpwe/LabROSA/db/CUAVE/

7. **AVLetters**
- Description: A dataset of video sequences of speakers saying letters, recorded with a low-quality camera and synchronized audio.
- Link: http://www.robots.ox.ac.uk/~vgg/data/lip_reading/lipreading-in-the-wild.html

8. **LRW-1000**
- Description: A dataset of video sequences of speakers saying words from a closed-set vocabulary, recorded with a high-quality camera and synchronized audio.
- Link: http://www.robots.ox.ac.uk/~vgg/data/lip_reading/lrw1000.html

9. **LRW-4000**
- Description: A larger version of the LRW dataset, containing 4,000 video sequences.
- Link: http://www.robots.ox.ac.uk/~vgg/data/lip_reading/lrw4000.html

10. **LRW-20**
- Description: A small version of the LRW dataset, containing 20 video sequences.
- Link: http://www.robots.ox.ac.uk/~vgg/data/lip_reading/lrw20.html
